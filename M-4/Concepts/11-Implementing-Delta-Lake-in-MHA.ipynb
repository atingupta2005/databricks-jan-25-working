{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28b6b500",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "# **Implementing Delta Lake in Multi-Hop Architectures - Concepts**\n",
    "\n",
    "## **Introduction**\n",
    "Modern data architectures require **scalability, reliability, and structured data processing**. The **Multi-Hop Architecture** (also known as the **Medallion Architecture**) provides a layered approach to **incrementally refine raw data into high-quality, analytics-ready datasets**. **Delta Lake** is the ideal framework for implementing such architectures due to its support for **ACID transactions, schema evolution, Change Data Capture (CDC), time travel, and performance optimizations**.\n",
    "\n",
    "This document provides an **in-depth exploration** of:\n",
    "- **Understanding Multi-Hop Architectures (Bronze, Silver, Gold Layers)**\n",
    "- **Advantages of using Delta Lake in Multi-Hop Pipelines**\n",
    "- **Detailed Implementation of Delta Lake in each layer**\n",
    "- **Schema Evolution, Time Travel, and Change Data Capture (CDC)**\n",
    "- **Performance Optimization with Compaction, Z-Ordering, and Auto Loader**\n",
    "- **Best Practices for Efficient Multi-Hop Architectures**\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Understanding Multi-Hop Architectures (Bronze, Silver, Gold Layers)**\n",
    "### **1.1 What is a Multi-Hop Architecture?**\n",
    "A **Multi-Hop Architecture** consists of three layers where data is progressively refined and structured for analytics and machine learning.\n",
    "\n",
    "| Layer  | Purpose | Characteristics |\n",
    "|--------|---------|-----------------|\n",
    "| **Bronze (Raw Data Layer)** | Stores raw, unprocessed data from multiple sources | Append-only, unstructured, schema-on-read |\n",
    "| **Silver (Cleaned & Processed Data)** | Cleansed, deduplicated, and transformed data | Schema enforcement, incremental processing, optimized for queries |\n",
    "| **Gold (Curated & Aggregated Data)** | Business-ready, aggregated data | Optimized for BI, dashboards, and ML workloads |\n",
    "\n",
    "### **1.2 Advantages of Using Delta Lake in Multi-Hop Architectures**\n",
    "- **Reliability with ACID Transactions**: Ensures consistency across transformations.\n",
    "- **Scalable Incremental Processing**: Avoids full table scans, supports CDC.\n",
    "- **Data Quality & Governance**: Schema enforcement prevents corruption.\n",
    "- **Optimized Query Performance**: Uses **Z-Ordering, partitioning, and compaction**.\n",
    "- **Supports Time Travel & Change Tracking**: Enables versioning for auditing and rollback.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Implementing Delta Lake in Multi-Hop Pipelines**\n",
    "### **2.1 Loading Data into the Bronze Layer (Raw Data Storage)**\n",
    "The **Bronze Layer** is the landing zone for all raw data from streaming and batch sources such as **Kafka, Event Hubs, IoT devices, and cloud storage**.\n",
    "\n",
    "#### **Example: Ingesting Data from Kafka into Bronze Layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aface424",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"BronzeLayerIngestion\").getOrCreate()\n",
    "\n",
    "bronze_df = spark.readStream.format(\"kafka\")\\\n",
    "    .option(\"kafka.bootstrap.servers\", \"localhost:9092\")\\\n",
    "    .option(\"subscribe\", \"transactions\")\\\n",
    "    .option(\"startingOffsets\", \"earliest\")\\\n",
    "    .load()\n",
    "\n",
    "bronze_df.writeStream.format(\"delta\")\\\n",
    "    .option(\"checkpointLocation\", \"/mnt/delta/bronze_checkpoint\")\\\n",
    "    .start(\"/mnt/delta/bronze_transactions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac66de2",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "**Key Features of the Bronze Layer:**\n",
    "- **Append-only immutable storage**.\n",
    "- **Raw format with minimal transformation**.\n",
    "- **Schema-on-read allows flexibility.**\n",
    "\n",
    "---\n",
    "\n",
    "### **2.2 Processing Data in the Silver Layer (Data Cleansing & Enrichment)**\n",
    "The **Silver Layer** refines the raw data, performing **schema enforcement, deduplication, and incremental updates**.\n",
    "\n",
    "#### **Example: Cleaning & Deduplicating Data in Silver Layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d275114d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from delta.tables import DeltaTable\n",
    "\n",
    "bronze_table = DeltaTable.forPath(spark, \"/mnt/delta/bronze_transactions\")\n",
    "\n",
    "silver_df = bronze_table.toDF().dropDuplicates([\"transaction_id\"]).filter(\"amount IS NOT NULL\")\n",
    "\n",
    "silver_df.write.format(\"delta\").mode(\"overwrite\").save(\"/mnt/delta/silver_transactions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9493c01f",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "**Key Features of the Silver Layer:**\n",
    "- **Removes duplicates and null values.**\n",
    "- **Enforces schema consistency.**\n",
    "- **Incrementally processes data using Change Data Capture (CDC).**\n",
    "\n",
    "---\n",
    "\n",
    "### **2.3 Generating Curated Data in the Gold Layer (Aggregated & Business-Ready)**\n",
    "The **Gold Layer** is optimized for business intelligence and machine learning by **aggregating and structuring** the cleansed data.\n",
    "\n",
    "#### **Example: Aggregating Sales Data in Gold Layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6225d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_df = spark.read.format(\"delta\").load(\"/mnt/delta/silver_transactions\")\\\n",
    "    .groupBy(\"customer_id\", \"transaction_date\")\\\n",
    "    .agg({\"amount\": \"sum\"})\\\n",
    "    .withColumnRenamed(\"sum(amount)\", \"total_spent\")\n",
    "\n",
    "gold_df.write.format(\"delta\").mode(\"overwrite\").save(\"/mnt/delta/gold_transactions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932a34ad",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "**Key Features of the Gold Layer:**\n",
    "- **Optimized for BI & ML workloads.**\n",
    "- **Precomputed aggregates for faster queries.**\n",
    "- **Serves dashboards and real-time analytics.**\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Advanced Features for Delta Lake Optimization**\n",
    "### **3.1 Schema Evolution & Enforcement**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e370c3",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "ALTER TABLE silver_transactions SET TBLPROPERTIES ('delta.columnMapping.mode' = 'name');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09583007",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "- **Prevents schema mismatches across layers.**\n",
    "- **Enforces backward compatibility for evolving schemas.**\n",
    "\n",
    "### **3.2 Change Data Capture (CDC) Implementation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb4fe1f",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "cdc_df = spark.readStream.format(\"delta\")\\\n",
    "    .option(\"readChangeFeed\", \"true\")\\\n",
    "    .table(\"silver_transactions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd2fed2",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "- **Processes incremental changes efficiently.**\n",
    "- **Enables real-time updates across layers.**\n",
    "\n",
    "### **3.3 Enabling Time Travel for Auditing & Recovery**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75655723",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT * FROM silver_transactions VERSION AS OF 5;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7d6a45",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "- **Retrieves previous versions for compliance audits.**\n",
    "- **Allows rollback of erroneous changes.**\n",
    "\n",
    "### **3.4 Performance Optimization using Compaction & Z-Ordering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebdd3a2",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "spark.sql(\"OPTIMIZE gold_transactions ZORDER BY customer_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0215fc0c",
   "metadata": {},
   "source": [
    "- **Reduces small file fragmentation.**\n",
    "- **Improves query efficiency by co-locating similar data.**\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Best Practices for Implementing Multi-Hop Delta Lake Pipelines**\n",
    "- **Use Auto Loader for continuous streaming ingestion.**\n",
    "- **Leverage Delta Lakeâ€™s built-in CDC for incremental updates.**\n",
    "- **Partition data based on query access patterns.**\n",
    "- **Optimize Delta tables using `OPTIMIZE` and `VACUUM`.**\n",
    "- **Implement access controls and data governance with Unity Catalog.**\n",
    "\n",
    "---\n",
    "\n",
    "## **Conclusion**\n",
    "Delta Lake provides a **scalable, structured, and efficient** foundation for **Multi-Hop Architectures**, enabling **reliable data processing, real-time analytics, and cost optimization**. By leveraging **schema enforcement, CDC, and performance tuning**, organizations can build **highly efficient, structured, and optimized data lakes** that support **enterprise-grade analytics and AI workloads**.\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
