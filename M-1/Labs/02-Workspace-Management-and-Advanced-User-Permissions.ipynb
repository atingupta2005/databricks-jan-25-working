{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30fe2170",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "# **Databricks Workspace Management & Advanced User Permissions - Lab Guide**\n",
    "\n",
    "## **Introduction**\n",
    "This lab guide provides a **detailed hands-on approach** to managing workspaces, configuring user permissions, enforcing security policies, and automating Databricks access controls at an **enterprise level**.\n",
    "\n",
    "By completing these labs, you will learn how to:\n",
    "1. **Create and manage users, groups, and roles** programmatically and via UI.\n",
    "2. **Assign permissions using Unity Catalog for enterprise-wide governance.**\n",
    "3. **Configure and test row-level security, column masking, and access control lists.**\n",
    "4. **Automate workspace setup using APIs, Terraform, and Databricks CLI.**\n",
    "5. **Implement enterprise security policies like MFA, IP whitelisting, and logging.**\n",
    "6. **Monitor and audit workspace activity for compliance enforcement.**\n",
    "7. **Manage Databricks workflows, clusters, and job permissions dynamically.**\n",
    "\n",
    "These labs **simulate real-world enterprise use cases**, ensuring **practical hands-on proficiency** in workspace security and governance.\n",
    "\n",
    "---\n",
    "\n",
    "## **Lab 1: User, Group & Role Management in Databricks**\n",
    "\n",
    "### **Step 1: Adding Users via UI**\n",
    "1. Navigate to **Databricks Admin Console**.\n",
    "2. Click **User Management → Add User**.\n",
    "3. Enter the user's email address.\n",
    "4. Assign a role:\n",
    "   - `Workspace Admin`\n",
    "   - `Data Engineer`\n",
    "   - `Data Scientist`\n",
    "   - `Analyst`\n",
    "5. Click **Create User**.\n",
    "\n",
    "### **Step 2: Creating Groups & Assigning Users**\n",
    "1. Navigate to **Groups → Create New Group**.\n",
    "2. Name the group (e.g., `Data Engineers`).\n",
    "3. Add users to the group.\n",
    "4. Assign **cluster, notebook, and job permissions** to the group.\n",
    "5. Click **Create**.\n",
    "\n",
    "### **Step 3: Managing Users & Groups via API**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d308381",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%python\n",
    "import requests\n",
    "TOKEN = \"<DATABRICKS_ACCESS_TOKEN>\"\n",
    "DATABRICKS_URL = \"https://<databricks-instance>.cloud.databricks.com/api/2.0/groups/list\"\n",
    "headers = {\"Authorization\": f\"Bearer {TOKEN}\"}\n",
    "response = requests.get(DATABRICKS_URL, headers=headers)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ed530e",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "---\n",
    "\n",
    "## **Lab 2: Unity Catalog - Fine-Grained Access Control**\n",
    "\n",
    "### **Step 1: Granting Table-Level Access**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5e56de",
   "metadata": {},
   "outputs": [],
   "source": [
    "GRANT SELECT ON TABLE transactions TO `data_analyst@example.com`;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037d4e07",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### **Step 2: Assigning Schema & Catalog Permissions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4204f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "GRANT USAGE ON SCHEMA finance TO `finance_team`;\n",
    "GRANT SELECT ON CATALOG enterprise_data TO `data_engineer@example.com`;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd66909",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### **Step 3: Implementing Row-Level Security (RLS)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546ca42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CREATE ROW ACCESS POLICY region_restrict \n",
    "ON sales_data\n",
    "USING (current_user() = 'user@example.com');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cdaafe",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### **Step 4: Enforcing Column-Level Masking for PII Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8561fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALTER TABLE customer_info \n",
    "ALTER COLUMN ssn SET MASKING POLICY mask_ssn_policy;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ee6458",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "---\n",
    "\n",
    "## **Lab 3: Automating Workspace Setup Using APIs & Terraform**\n",
    "\n",
    "### **Step 1: Creating a Cluster via API**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0ce3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%python\n",
    "import requests\n",
    "TOKEN = \"<DATABRICKS_ACCESS_TOKEN>\"\n",
    "DATABRICKS_URL = \"https://<databricks-instance>.cloud.databricks.com/api/2.0/clusters/create\"\n",
    "headers = {\"Authorization\": f\"Bearer {TOKEN}\", \"Content-Type\": \"application/json\"}\n",
    "\n",
    "cluster_config = {\n",
    "  \"cluster_name\": \"Production Cluster\",\n",
    "  \"spark_version\": \"11.3.x-scala2.12\",\n",
    "  \"node_type_id\": \"Standard_DS3_v2\",\n",
    "  \"num_workers\": 5\n",
    "}\n",
    "\n",
    "response = requests.post(DATABRICKS_URL, headers=headers, json=cluster_config)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bcb7e2",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### **Step 2: Assigning Notebook Permissions via API**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2141bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%python\n",
    "notebook_permissions = {\n",
    "  \"access_control_list\": [{\"user_name\": \"user@example.com\", \"permission_level\": \"CAN_RUN\"}]\n",
    "}\n",
    "requests.put(f\"{DATABRICKS_URL}/api/2.0/permissions/notebooks/<notebook_id>\", headers=headers, json=notebook_permissions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7639442b",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### **Step 3: Automating Workspace Setup Using Terraform**\n",
    "```hcl\n",
    "resource \"databricks_permissions\" \"finance_table\" {\n",
    "  table = \"finance_data\"\n",
    "  access_control {\n",
    "    user_name = \"analyst@example.com\"\n",
    "    permission_level = \"CAN_SELECT\"\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **Lab 4: Implementing Enterprise-Grade Security Policies**\n",
    "\n",
    "### **Step 1: Enforcing Multi-Factor Authentication (MFA)**\n",
    "1. Navigate to **Databricks Account Settings**.\n",
    "2. Click **Security Settings → Enable MFA**.\n",
    "3. Require all workspace admins to use **Multi-Factor Authentication**.\n",
    "\n",
    "### **Step 2: Configuring IP Whitelisting**\n",
    "Restrict access to Databricks from specific corporate IPs.\n",
    "```json\n",
    "{\n",
    "  \"ip_access_list\": [\n",
    "    {\"ip_address\": \"192.168.1.1/32\", \"label\": \"Allowed Office IP\"}\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\n",
    "### **Step 3: Enabling Audit Logging**\n",
    "1. Go to **Databricks Admin Console → Logs**.\n",
    "2. Enable **Audit Logging to Azure Monitor or AWS CloudTrail**.\n",
    "3. Run queries to monitor access patterns.\n",
    "\n",
    "### **Step 4: Monitoring User Activity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f990a020",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT * FROM system.audit_logs WHERE action = 'QUERY_EXECUTED';"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa7f8be",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "---\n",
    "\n",
    "## **Lab 5: Managing Job & Workflow Permissions**\n",
    "\n",
    "### **Step 1: Creating a Job with User Restrictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5210de22",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%python\n",
    "job_config = {\n",
    "  \"name\": \"Daily ETL Process\",\n",
    "  \"tasks\": [{\n",
    "    \"task_key\": \"load_data\",\n",
    "    \"notebook_task\": {\n",
    "      \"notebook_path\": \"/Repos/etl_pipeline\"\n",
    "    },\n",
    "    \"existing_cluster_id\": \"<Cluster_ID>\",\n",
    "    \"permissions\": [{\"user_name\": \"analyst@example.com\", \"permission_level\": \"CAN_VIEW\"}]\n",
    "  }]\n",
    "}\n",
    "requests.post(f\"{DATABRICKS_URL}/api/2.0/jobs/create\", headers=headers, json=job_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddfb37a",
   "metadata": {},
   "source": [
    "### **Step 2: Assigning Job Permissions via UI**\n",
    "1. Navigate to **Jobs → Select Job**.\n",
    "2. Click **Permissions → Assign Roles**.\n",
    "3. Grant `CAN_MANAGE`, `CAN_VIEW`, or `CAN_RUN`.\n",
    "\n",
    "---\n",
    "\n",
    "## **Conclusion**\n",
    "These labs provide hands-on experience in:\n",
    "- **Managing users, groups, and RBAC effectively**.\n",
    "- **Configuring Unity Catalog for governance & security**.\n",
    "- **Automating Databricks workspace setup using Terraform & APIs**.\n",
    "- **Enforcing security best practices across the Databricks environment**.\n",
    "- **Managing job and workflow permissions dynamically**.\n",
    "\n",
    "By mastering these labs, you ensure a **secure, compliant, and scalable** Databricks deployment for enterprise-level data processing and analytics.\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "sql",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
