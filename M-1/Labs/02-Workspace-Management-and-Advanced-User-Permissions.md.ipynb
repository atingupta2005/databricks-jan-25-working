{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Databricks Workspace Management & Advanced User Permissions - Lab Guide**\n",
    "\n",
    "## **Introduction**\n",
    "\n",
    "This lab guide provides a **detailed hands-on approach** to managing\n",
    "workspaces, configuring user permissions, enforcing security policies,\n",
    "and automating Databricks access controls at an **enterprise level**.\n",
    "\n",
    "By completing these labs, you will learn how to: 1. **Create and manage\n",
    "users, groups, and roles** programmatically and via UI. 2. **Assign\n",
    "permissions using Unity Catalog for enterprise-wide governance.** 3.\n",
    "**Configure and test row-level security, column masking, and access\n",
    "control lists.** 4. **Automate workspace setup using APIs, Terraform,\n",
    "and Databricks CLI.** 5. **Implement enterprise security policies like\n",
    "MFA, IP whitelisting, and logging.** 6. **Monitor and audit workspace\n",
    "activity for compliance enforcement.** 7. **Manage Databricks workflows,\n",
    "clusters, and job permissions dynamically.**\n",
    "\n",
    "These labs **simulate real-world enterprise use cases**, ensuring\n",
    "**practical hands-on proficiency** in workspace security and governance.\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "## **Lab 1: User, Group & Role Management in Databricks**\n",
    "\n",
    "### **Step 1: Adding Users via UI**\n",
    "\n",
    "1.  Navigate to **Databricks Admin Console**.\n",
    "2.  Click **User Management → Add User**.\n",
    "3.  Enter the user’s email address.\n",
    "4.  Assign a role:\n",
    "    -   `Workspace Admin`\n",
    "    -   `Data Engineer`\n",
    "    -   `Data Scientist`\n",
    "    -   `Analyst`\n",
    "5.  Click **Create User**.\n",
    "\n",
    "### **Step 2: Creating Groups & Assigning Users**\n",
    "\n",
    "1.  Navigate to **Groups → Create New Group**.\n",
    "2.  Name the group (e.g., `Data Engineers`).\n",
    "3.  Add users to the group.\n",
    "4.  Assign **cluster, notebook, and job permissions** to the group.\n",
    "5.  Click **Create**.\n",
    "\n",
    "### **Step 3: Managing Users & Groups via API**\n",
    "\n",
    "``` python\n",
    "import requests\n",
    "TOKEN = \"<DATABRICKS_ACCESS_TOKEN>\"\n",
    "DATABRICKS_URL = \"https://<databricks-instance>.cloud.databricks.com/api/2.0/groups/list\"\n",
    "headers = {\"Authorization\": f\"Bearer {TOKEN}\"}\n",
    "response = requests.get(DATABRICKS_URL, headers=headers)\n",
    "print(response.json())\n",
    "```\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "## **Lab 2: Unity Catalog - Fine-Grained Access Control**\n",
    "\n",
    "### **Step 1: Granting Table-Level Access**\n",
    "\n",
    "``` sql\n",
    "GRANT SELECT ON TABLE transactions TO `data_analyst@example.com`;\n",
    "```\n",
    "\n",
    "### **Step 2: Assigning Schema & Catalog Permissions**\n",
    "\n",
    "``` sql\n",
    "GRANT USAGE ON SCHEMA finance TO `finance_team`;\n",
    "GRANT SELECT ON CATALOG enterprise_data TO `data_engineer@example.com`;\n",
    "```\n",
    "\n",
    "### **Step 3: Implementing Row-Level Security (RLS)**\n",
    "\n",
    "``` sql\n",
    "CREATE ROW ACCESS POLICY region_restrict \n",
    "ON sales_data\n",
    "USING (current_user() = 'user@example.com');\n",
    "```\n",
    "\n",
    "### **Step 4: Enforcing Column-Level Masking for PII Data**\n",
    "\n",
    "``` sql\n",
    "ALTER TABLE customer_info \n",
    "ALTER COLUMN ssn SET MASKING POLICY mask_ssn_policy;\n",
    "```\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "## **Lab 3: Automating Workspace Setup Using APIs & Terraform**\n",
    "\n",
    "### **Step 1: Creating a Cluster via API**\n",
    "\n",
    "``` python\n",
    "import requests\n",
    "TOKEN = \"<DATABRICKS_ACCESS_TOKEN>\"\n",
    "DATABRICKS_URL = \"https://<databricks-instance>.cloud.databricks.com/api/2.0/clusters/create\"\n",
    "headers = {\"Authorization\": f\"Bearer {TOKEN}\", \"Content-Type\": \"application/json\"}\n",
    "\n",
    "cluster_config = {\n",
    "  \"cluster_name\": \"Production Cluster\",\n",
    "  \"spark_version\": \"11.3.x-scala2.12\",\n",
    "  \"node_type_id\": \"Standard_DS3_v2\",\n",
    "  \"num_workers\": 5\n",
    "}\n",
    "\n",
    "response = requests.post(DATABRICKS_URL, headers=headers, json=cluster_config)\n",
    "print(response.json())\n",
    "```\n",
    "\n",
    "### **Step 2: Assigning Notebook Permissions via API**\n",
    "\n",
    "``` python\n",
    "notebook_permissions = {\n",
    "  \"access_control_list\": [{\"user_name\": \"user@example.com\", \"permission_level\": \"CAN_RUN\"}]\n",
    "}\n",
    "requests.put(f\"{DATABRICKS_URL}/api/2.0/permissions/notebooks/<notebook_id>\", headers=headers, json=notebook_permissions)\n",
    "```\n",
    "\n",
    "### **Step 3: Automating Workspace Setup Using Terraform**\n",
    "\n",
    "``` hcl\n",
    "resource \"databricks_permissions\" \"finance_table\" {\n",
    "  table = \"finance_data\"\n",
    "  access_control {\n",
    "    user_name = \"analyst@example.com\"\n",
    "    permission_level = \"CAN_SELECT\"\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "## **Lab 4: Implementing Enterprise-Grade Security Policies**\n",
    "\n",
    "### **Step 1: Enforcing Multi-Factor Authentication (MFA)**\n",
    "\n",
    "1.  Navigate to **Databricks Account Settings**.\n",
    "2.  Click **Security Settings → Enable MFA**.\n",
    "3.  Require all workspace admins to use **Multi-Factor Authentication**.\n",
    "\n",
    "### **Step 2: Configuring IP Whitelisting**\n",
    "\n",
    "Restrict access to Databricks from specific corporate IPs.\n",
    "\n",
    "``` json\n",
    "{\n",
    "  \"ip_access_list\": [\n",
    "    {\"ip_address\": \"192.168.1.1/32\", \"label\": \"Allowed Office IP\"}\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\n",
    "### **Step 3: Enabling Audit Logging**\n",
    "\n",
    "1.  Go to **Databricks Admin Console → Logs**.\n",
    "2.  Enable **Audit Logging to Azure Monitor or AWS CloudTrail**.\n",
    "3.  Run queries to monitor access patterns.\n",
    "\n",
    "### **Step 4: Monitoring User Activity**\n",
    "\n",
    "``` sql\n",
    "SELECT * FROM system.audit_logs WHERE action = 'QUERY_EXECUTED';\n",
    "```\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "## **Lab 5: Managing Job & Workflow Permissions**\n",
    "\n",
    "### **Step 1: Creating a Job with User Restrictions**\n",
    "\n",
    "``` python\n",
    "job_config = {\n",
    "  \"name\": \"Daily ETL Process\",\n",
    "  \"tasks\": [{\n",
    "    \"task_key\": \"load_data\",\n",
    "    \"notebook_task\": {\n",
    "      \"notebook_path\": \"/Repos/etl_pipeline\"\n",
    "    },\n",
    "    \"existing_cluster_id\": \"<Cluster_ID>\",\n",
    "    \"permissions\": [{\"user_name\": \"analyst@example.com\", \"permission_level\": \"CAN_VIEW\"}]\n",
    "  }]\n",
    "}\n",
    "requests.post(f\"{DATABRICKS_URL}/api/2.0/jobs/create\", headers=headers, json=job_config)\n",
    "```\n",
    "\n",
    "### **Step 2: Assigning Job Permissions via UI**\n",
    "\n",
    "1.  Navigate to **Jobs → Select Job**.\n",
    "2.  Click **Permissions → Assign Roles**.\n",
    "3.  Grant `CAN_MANAGE`, `CAN_VIEW`, or `CAN_RUN`.\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "## **Conclusion**\n",
    "\n",
    "These labs provide hands-on experience in: - **Managing users, groups,\n",
    "and RBAC effectively**. - **Configuring Unity Catalog for governance &\n",
    "security**. - **Automating Databricks workspace setup using Terraform &\n",
    "APIs**. - **Enforcing security best practices across the Databricks\n",
    "environment**. - **Managing job and workflow permissions dynamically**.\n",
    "\n",
    "By mastering these labs, you ensure a **secure, compliant, and\n",
    "scalable** Databricks deployment for enterprise-level data processing\n",
    "and analytics."
   ],
   "id": "d8dda93a-4561-4eaf-b416-073e6734819e"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
