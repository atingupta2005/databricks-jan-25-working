{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Adaptive Query Execution (AQE) - Hands-on Labs**\n",
    "\n",
    "## **Introduction**\n",
    "\n",
    "This hands-on lab document provides **detailed, step-by-step exercises**\n",
    "to implement and optimize **Adaptive Query Execution (AQE)** in Apache\n",
    "Spark and **Databricks**. These labs will cover: - **Enabling AQE and\n",
    "key configurations** - **Optimizing shuffle partitions dynamically** -\n",
    "**Implementing adaptive join strategies** - **Handling data skew\n",
    "effectively** - **Monitoring and troubleshooting AQE performance**\n",
    "\n",
    "Each lab includes **real-world examples**, **step-by-step\n",
    "instructions**, and **sample dataset usage** (Banks Data, Loan\n",
    "Foreclosure Data, Flights Data from previous notebooks) to ensure\n",
    "**efficient query execution**.\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "## **Lab 1: Enabling AQE and Configurations**\n",
    "\n",
    "### **Objective:**\n",
    "\n",
    "-   Enable and verify **Adaptive Query Execution (AQE)** in\n",
    "    **Databricks**.\n",
    "\n",
    "### **Step 1: Enable AQE in Databricks**\n",
    "\n",
    "``` python\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"AQE_Optimization\") \\\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    "    .getOrCreate()\n",
    "```\n",
    "\n",
    "### **Step 2: Verify AQE Configuration**\n",
    "\n",
    "``` python\n",
    "print(\"AQE Enabled:\", spark.conf.get(\"spark.sql.adaptive.enabled\"))\n",
    "```\n",
    "\n",
    "**Expected Outcome:** - AQE is successfully **enabled** and **ready for\n",
    "execution optimizations**.\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "## **Lab 2: Optimizing Shuffle Partitions with AQE**\n",
    "\n",
    "### **Objective:**\n",
    "\n",
    "-   Use **AQE to dynamically adjust shuffle partitions** based on data\n",
    "    size.\n",
    "\n",
    "### **Step 1: Load Sample Data** (Flights Data)\n",
    "\n",
    "``` python\n",
    "df = spark.read.format(\"delta\").load(\"abfss://datalake@storage.dfs.core.windows.net/flights_data\")\n",
    "```\n",
    "\n",
    "### **Step 2: Enable Dynamic Shuffle Partitioning**\n",
    "\n",
    "``` python\n",
    "spark.conf.set(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\")\n",
    "spark.conf.set(\"spark.sql.adaptive.coalescePartitions.minPartitionSize\", \"64MB\")\n",
    "```\n",
    "\n",
    "### **Step 3: Execute and Observe Changes**\n",
    "\n",
    "``` python\n",
    "result = df.groupBy(\"flight_id\").count().collect()\n",
    "print(\"Query Execution Completed Successfully\")\n",
    "```\n",
    "\n",
    "**Expected Outcome:** - Spark **dynamically adjusts** shuffle partitions\n",
    "to **optimize performance** and **reduce costs**.\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "## **Lab 3: Implementing Adaptive Join Strategies**\n",
    "\n",
    "### **Objective:**\n",
    "\n",
    "-   Dynamically **switch join types** to optimize execution.\n",
    "\n",
    "### **Step 1: Enable Adaptive Joins**\n",
    "\n",
    "``` python\n",
    "spark.conf.set(\"spark.sql.adaptive.join.enabled\", \"true\")\n",
    "```\n",
    "\n",
    "### **Step 2: Load Sample Datasets (Banks and Loan Data)**\n",
    "\n",
    "``` python\n",
    "df_banks = spark.read.format(\"delta\").load(\"abfss://datalake@storage.dfs.core.windows.net/banks_data\")\n",
    "df_loans = spark.read.format(\"delta\").load(\"abfss://datalake@storage.dfs.core.windows.net/loan_foreclosure\")\n",
    "```\n",
    "\n",
    "### **Step 3: Perform Join and Observe AQE Behavior**\n",
    "\n",
    "``` python\n",
    "joined_df = df_loans.join(df_banks, \"bank_id\")\n",
    "joined_df.show(5)\n",
    "```\n",
    "\n",
    "**Expected Outcome:** - **AQE dynamically switches** from **shuffle\n",
    "join** to **broadcast join** when applicable, reducing shuffle overhead.\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "## **Lab 4: Handling Data Skew with AQE**\n",
    "\n",
    "### **Objective:**\n",
    "\n",
    "-   Optimize queries by **handling data skew dynamically**.\n",
    "\n",
    "### **Step 1: Enable Skew Join Optimization**\n",
    "\n",
    "``` python\n",
    "spark.conf.set(\"spark.sql.adaptive.skewJoin.enabled\", \"true\")\n",
    "```\n",
    "\n",
    "### **Step 2: Load Skewed Data (Loan Foreclosure Data)**\n",
    "\n",
    "``` python\n",
    "df_loans_skewed = spark.read.format(\"delta\").load(\"abfss://datalake@storage.dfs.core.windows.net/loan_foreclosure_skewed\")\n",
    "```\n",
    "\n",
    "### **Step 3: Execute Query and Monitor Execution Plan**\n",
    "\n",
    "``` python\n",
    "from pyspark.sql.functions import col\n",
    "result = df_loans_skewed.groupBy(\"loan_status\").count()\n",
    "result.explain(True)\n",
    "```\n",
    "\n",
    "**Expected Outcome:** - AQE **automatically splits skewed partitions**,\n",
    "ensuring **better parallelism and query efficiency**.\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "## **Lab 5: Monitoring AQE Execution Plans**\n",
    "\n",
    "### **Objective:**\n",
    "\n",
    "-   Understand **how AQE modifies query execution plans**.\n",
    "\n",
    "### **Step 1: Enable AQE Execution Plan Logging**\n",
    "\n",
    "``` python\n",
    "spark.conf.set(\"spark.sql.adaptive.logLevel\", \"INFO\")\n",
    "```\n",
    "\n",
    "### **Step 2: Execute a Complex Query with AQE**\n",
    "\n",
    "``` python\n",
    "df_complex = df_loans_skewed.groupBy(\"loan_purpose\").agg({\"loan_amount\": \"avg\"})\n",
    "df_complex.explain(True)\n",
    "```\n",
    "\n",
    "### **Step 3: Compare Execution Plan Changes**\n",
    "\n",
    "-   Observe **shuffle partition coalescing**.\n",
    "-   Identify **adaptive join strategy selection**.\n",
    "-   Check for **skew join optimizations**.\n",
    "\n",
    "**Expected Outcome:** - The execution plan **shows AQE optimizations**,\n",
    "proving its effectiveness in runtime tuning.\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "## **Conclusion**\n",
    "\n",
    "By completing these **hands-on labs**, you have learned how to: -\n",
    "**Enable and configure AQE** in **Databricks**. - **Optimize shuffle\n",
    "partitions dynamically** to improve query performance. - **Leverage\n",
    "adaptive join strategies** to reduce shuffle overhead. - **Handle data\n",
    "skew automatically** to prevent slow-running queries. - **Monitor and\n",
    "analyze AQE execution plans** for performance tuning.\n",
    "\n",
    "These labs provide **real-world experience** in leveraging **Adaptive\n",
    "Query Execution (AQE) for Spark query optimization**, making **data\n",
    "processing faster, more efficient, and cost-effective**."
   ],
   "id": "0e0cb2ec-e97f-4568-8dd0-c4054d3985e1"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
