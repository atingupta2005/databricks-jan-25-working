{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf5440b2",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "# **Managing Shuffles and Broadcast Joins - Concepts**\n",
    "\n",
    "## **Introduction**\n",
    "Apache Spark is designed to process large-scale data efficiently. However, inefficient shuffling and poor join strategies can lead to performance bottlenecks. **Managing shuffles and broadcast joins effectively** is crucial for optimizing **query execution speed, reducing memory usage, and minimizing network overhead**.\n",
    "\n",
    "This document provides a **detailed guide** on managing **shuffles and broadcast joins** in **Databricks and cloud-based Spark environments**. It covers:\n",
    "- **Understanding shuffling in Spark** and its impact on performance\n",
    "- **Techniques to optimize shuffling using partitioning and caching**\n",
    "- **Understanding broadcast joins and when to use them**\n",
    "- **Best practices for managing large-scale joins efficiently**\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Understanding Shuffling in Spark**\n",
    "### **1.1 What is Shuffling?**\n",
    "Shuffling in Spark occurs when data is **redistributed across nodes** due to operations such as **groupBy, join, and repartition**. It involves:\n",
    "- **Data movement across the cluster**.\n",
    "- **Read/write operations to disk and network**.\n",
    "- **Increased memory and execution time**.\n",
    "\n",
    "### **1.2 Common Causes of Shuffling**\n",
    "| Cause | Description |\n",
    "|----------------|--------------------------------|\n",
    "| **groupBy / reduceBy** | Redistributes data based on a key to perform aggregations. |\n",
    "| **Joins on large datasets** | Requires data movement if keys are not co-located. |\n",
    "| **Repartitioning / coalesce** | Adjusts partition numbers, triggering data movement. |\n",
    "| **Distinct operations** | Requires deduplication across partitions. |\n",
    "\n",
    "### **1.3 Problems Caused by Excessive Shuffling**\n",
    "- **Increased query execution time** due to high I/O operations.\n",
    "- **Memory spills leading to OutOfMemory (OOM) errors**.\n",
    "- **Network congestion slowing down distributed processing**.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Optimizing Shuffling in Spark**\n",
    "### **2.1 Using Proper Partitioning Strategies**\n",
    "- **Hash Partitioning**: Distributes data based on hash functions, useful for joins and aggregations.\n",
    "- **Range Partitioning**: Splits data based on a sorting order, beneficial for ordered operations.\n",
    "- **Bucket Partitioning**: Pre-partitions tables to reduce shuffle during joins.\n",
    "\n",
    "#### **Example: Hash Partitioning for Efficient Joins**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9223d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.shuffle.partitions\", \"200\")\n",
    "df = df.repartition(\"customer_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d908e13f",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### **2.2 Using Coalesce vs. Repartition**\n",
    "- **`repartition(n)`** increases partitions but triggers **full shuffle**.\n",
    "- **`coalesce(n)`** reduces partitions without triggering full shuffle, better for reducing data movement.\n",
    "\n",
    "#### **Example: Using Coalesce to Optimize Data Movement**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32ceff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.coalesce(10)  # Reduces shuffle cost while merging partitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb5599a",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "---\n",
    "\n",
    "## **3. Understanding Broadcast Joins**\n",
    "### **3.1 What is a Broadcast Join?**\n",
    "A **broadcast join** occurs when **one dataset is small enough** to be sent to all nodes in the cluster, avoiding shuffling the large dataset.\n",
    "\n",
    "### **3.2 When to Use Broadcast Joins**\n",
    "| Scenario | Benefit |\n",
    "|----------|---------|\n",
    "| Small lookup tables | Avoids shuffling large datasets |\n",
    "| Star-schema joins | Improves performance by sending small dimensions to workers |\n",
    "| One dataset is significantly smaller | Minimizes network movement |\n",
    "\n",
    "### **3.3 Enabling Broadcast Joins in Spark**\n",
    "By default, Spark **automatically** chooses broadcast joins if a dataset is **smaller than 10MB**.\n",
    "- **Manually enabling broadcast join** for larger datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c50d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import broadcast\n",
    "df_joined = df_large.join(broadcast(df_small), \"customer_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b91f91",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "- **Increasing the broadcast threshold**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502df3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", \"50MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf4a447",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "**Advantages:**\n",
    "- **Eliminates shuffle for the smaller dataset**.\n",
    "- **Improves query execution speed significantly**.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Best Practices for Managing Shuffles and Joins**\n",
    "### **4.1 Best Practices for Reducing Shuffles**\n",
    "- **Minimize the number of shuffle operations** by caching frequently used datasets.\n",
    "- **Use partitioning techniques** to colocate data in the same partitions.\n",
    "- **Avoid unnecessary repartitioning** unless required for performance tuning.\n",
    "- **Use proper aggregation methods (reduceByKey instead of groupByKey).**\n",
    "\n",
    "### **4.2 Best Practices for Broadcast Joins**\n",
    "- **Broadcast only small datasets** to avoid memory pressure.\n",
    "- **Monitor and tune the autoBroadcastJoinThreshold** based on cluster capacity.\n",
    "- **Use `EXPLAIN` to check if Spark is performing a broadcast join**.\n",
    "\n",
    "#### **Example: Checking Query Plan for Broadcast Joins**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fb5e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joined.explain(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9fbc7d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Conclusion**\n",
    "Effectively managing **shuffles and broadcast joins** can **drastically improve Spark job performance** by minimizing data movement and optimizing query execution.\n",
    "\n",
    "Key takeaways:\n",
    "- **Shuffling increases computation cost** and should be minimized using **partitioning strategies**.\n",
    "- **Broadcast joins eliminate unnecessary shuffling**, making them ideal for **small lookup tables**.\n",
    "- **Fine-tuning partition sizes, using coalesce, and leveraging caching** can further **optimize performance**.\n",
    "\n",
    "By applying these best practices, organizations can **optimize data engineering workloads, reduce processing time, and lower infrastructure costs** in **Databricks and other Spark-based environments**.\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
